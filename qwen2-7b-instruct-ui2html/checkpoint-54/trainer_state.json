{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 54,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.018518518518518517,
      "grad_norm": 0.14098985493183136,
      "learning_rate": 0.0002,
      "loss": 0.8818,
      "step": 1
    },
    {
      "epoch": 0.037037037037037035,
      "grad_norm": 0.10721324384212494,
      "learning_rate": 0.0002,
      "loss": 1.0238,
      "step": 2
    },
    {
      "epoch": 0.05555555555555555,
      "grad_norm": 0.08004146814346313,
      "learning_rate": 0.0002,
      "loss": 0.7395,
      "step": 3
    },
    {
      "epoch": 0.07407407407407407,
      "grad_norm": 0.08580842614173889,
      "learning_rate": 0.0002,
      "loss": 0.9096,
      "step": 4
    },
    {
      "epoch": 0.09259259259259259,
      "grad_norm": 0.09254321455955505,
      "learning_rate": 0.0002,
      "loss": 0.7741,
      "step": 5
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 0.15072667598724365,
      "learning_rate": 0.0002,
      "loss": 1.2667,
      "step": 6
    },
    {
      "epoch": 0.12962962962962962,
      "grad_norm": 0.10683608800172806,
      "learning_rate": 0.0002,
      "loss": 1.1675,
      "step": 7
    },
    {
      "epoch": 0.14814814814814814,
      "grad_norm": 0.14824417233467102,
      "learning_rate": 0.0002,
      "loss": 0.8483,
      "step": 8
    },
    {
      "epoch": 0.16666666666666666,
      "grad_norm": 0.22021064162254333,
      "learning_rate": 0.0002,
      "loss": 1.1623,
      "step": 9
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 0.2285040020942688,
      "learning_rate": 0.0002,
      "loss": 1.0515,
      "step": 10
    },
    {
      "epoch": 0.2037037037037037,
      "grad_norm": 0.11756950616836548,
      "learning_rate": 0.0002,
      "loss": 0.695,
      "step": 11
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 0.11914803087711334,
      "learning_rate": 0.0002,
      "loss": 0.8206,
      "step": 12
    },
    {
      "epoch": 0.24074074074074073,
      "grad_norm": 0.08392218500375748,
      "learning_rate": 0.0002,
      "loss": 0.6867,
      "step": 13
    },
    {
      "epoch": 0.25925925925925924,
      "grad_norm": 0.13264110684394836,
      "learning_rate": 0.0002,
      "loss": 0.9822,
      "step": 14
    },
    {
      "epoch": 0.2777777777777778,
      "grad_norm": 0.1952412873506546,
      "learning_rate": 0.0002,
      "loss": 0.7993,
      "step": 15
    },
    {
      "epoch": 0.2962962962962963,
      "grad_norm": 0.3608782887458801,
      "learning_rate": 0.0002,
      "loss": 1.0129,
      "step": 16
    },
    {
      "epoch": 0.3148148148148148,
      "grad_norm": 0.2791411578655243,
      "learning_rate": 0.0002,
      "loss": 0.8348,
      "step": 17
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.21600712835788727,
      "learning_rate": 0.0002,
      "loss": 1.3372,
      "step": 18
    },
    {
      "epoch": 0.35185185185185186,
      "grad_norm": 0.3274162709712982,
      "learning_rate": 0.0002,
      "loss": 0.7919,
      "step": 19
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.189326211810112,
      "learning_rate": 0.0002,
      "loss": 0.9974,
      "step": 20
    },
    {
      "epoch": 0.3888888888888889,
      "grad_norm": 0.30016016960144043,
      "learning_rate": 0.0002,
      "loss": 1.0166,
      "step": 21
    },
    {
      "epoch": 0.4074074074074074,
      "grad_norm": 0.29322221875190735,
      "learning_rate": 0.0002,
      "loss": 1.185,
      "step": 22
    },
    {
      "epoch": 0.42592592592592593,
      "grad_norm": 0.19700737297534943,
      "learning_rate": 0.0002,
      "loss": 0.9355,
      "step": 23
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.23773859441280365,
      "learning_rate": 0.0002,
      "loss": 0.9251,
      "step": 24
    },
    {
      "epoch": 0.46296296296296297,
      "grad_norm": 0.19892767071723938,
      "learning_rate": 0.0002,
      "loss": 0.7568,
      "step": 25
    },
    {
      "epoch": 0.48148148148148145,
      "grad_norm": 0.19643273949623108,
      "learning_rate": 0.0002,
      "loss": 0.9516,
      "step": 26
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.30741390585899353,
      "learning_rate": 0.0002,
      "loss": 1.2081,
      "step": 27
    },
    {
      "epoch": 0.5185185185185185,
      "grad_norm": 0.27158689498901367,
      "learning_rate": 0.0002,
      "loss": 0.7296,
      "step": 28
    },
    {
      "epoch": 0.5370370370370371,
      "grad_norm": 0.46439898014068604,
      "learning_rate": 0.0002,
      "loss": 0.994,
      "step": 29
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.22109097242355347,
      "learning_rate": 0.0002,
      "loss": 0.5037,
      "step": 30
    },
    {
      "epoch": 0.5740740740740741,
      "grad_norm": 0.2415734827518463,
      "learning_rate": 0.0002,
      "loss": 1.9777,
      "step": 31
    },
    {
      "epoch": 0.5925925925925926,
      "grad_norm": 0.21965575218200684,
      "learning_rate": 0.0002,
      "loss": 0.9884,
      "step": 32
    },
    {
      "epoch": 0.6111111111111112,
      "grad_norm": 0.23649175465106964,
      "learning_rate": 0.0002,
      "loss": 0.969,
      "step": 33
    },
    {
      "epoch": 0.6296296296296297,
      "grad_norm": 0.18231359124183655,
      "learning_rate": 0.0002,
      "loss": 0.6868,
      "step": 34
    },
    {
      "epoch": 0.6481481481481481,
      "grad_norm": 0.2896861732006073,
      "learning_rate": 0.0002,
      "loss": 0.9636,
      "step": 35
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.20066779851913452,
      "learning_rate": 0.0002,
      "loss": 0.9973,
      "step": 36
    },
    {
      "epoch": 0.6851851851851852,
      "grad_norm": 0.375844269990921,
      "learning_rate": 0.0002,
      "loss": 1.3532,
      "step": 37
    },
    {
      "epoch": 0.7037037037037037,
      "grad_norm": 0.2643909156322479,
      "learning_rate": 0.0002,
      "loss": 0.9943,
      "step": 38
    },
    {
      "epoch": 0.7222222222222222,
      "grad_norm": 0.5623026490211487,
      "learning_rate": 0.0002,
      "loss": 0.8221,
      "step": 39
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.3967607021331787,
      "learning_rate": 0.0002,
      "loss": 1.3127,
      "step": 40
    },
    {
      "epoch": 0.7592592592592593,
      "grad_norm": 0.48147523403167725,
      "learning_rate": 0.0002,
      "loss": 0.9345,
      "step": 41
    },
    {
      "epoch": 0.7777777777777778,
      "grad_norm": 0.3321864902973175,
      "learning_rate": 0.0002,
      "loss": 0.7271,
      "step": 42
    },
    {
      "epoch": 0.7962962962962963,
      "grad_norm": 0.18484458327293396,
      "learning_rate": 0.0002,
      "loss": 0.8173,
      "step": 43
    },
    {
      "epoch": 0.8148148148148148,
      "grad_norm": 0.23769810795783997,
      "learning_rate": 0.0002,
      "loss": 0.7112,
      "step": 44
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 0.3088340163230896,
      "learning_rate": 0.0002,
      "loss": 1.1123,
      "step": 45
    },
    {
      "epoch": 0.8518518518518519,
      "grad_norm": 0.4691810607910156,
      "learning_rate": 0.0002,
      "loss": 0.6506,
      "step": 46
    },
    {
      "epoch": 0.8703703703703703,
      "grad_norm": 0.25494396686553955,
      "learning_rate": 0.0002,
      "loss": 0.8666,
      "step": 47
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.29909077286720276,
      "learning_rate": 0.0002,
      "loss": 0.9163,
      "step": 48
    },
    {
      "epoch": 0.9074074074074074,
      "grad_norm": 0.2345610111951828,
      "learning_rate": 0.0002,
      "loss": 0.7799,
      "step": 49
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.28749239444732666,
      "learning_rate": 0.0002,
      "loss": 0.8759,
      "step": 50
    },
    {
      "epoch": 0.9444444444444444,
      "grad_norm": 0.22751100361347198,
      "learning_rate": 0.0002,
      "loss": 0.9398,
      "step": 51
    },
    {
      "epoch": 0.9629629629629629,
      "grad_norm": 0.35869237780570984,
      "learning_rate": 0.0002,
      "loss": 1.0513,
      "step": 52
    },
    {
      "epoch": 0.9814814814814815,
      "grad_norm": 0.3429059088230133,
      "learning_rate": 0.0002,
      "loss": 1.0702,
      "step": 53
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.19404982030391693,
      "learning_rate": 0.0002,
      "loss": 0.6147,
      "step": 54
    }
  ],
  "logging_steps": 1,
  "max_steps": 54,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.016508631405056e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
