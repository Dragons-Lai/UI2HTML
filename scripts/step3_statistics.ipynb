{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"step3_statistics.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1--a2JUkBlN3Z26g1gaT_EglNLNuZJ6ZY\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8XwZuq3GAgY",
        "outputId": "cd376ca9-bd15-46d0-d9e8-f65233ac38e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,542 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,140 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,246 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,788 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n",
            "Get:17 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [73.0 kB]\n",
            "0% [15 Packages store 0 B]"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y chromium-chromedriver\n",
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXaqMZU8JH4W"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "from huggingface_hub import hf_hub_download\n",
        "from google.colab import files\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import display, HTML\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkgI8YtsJEvl"
      },
      "outputs": [],
      "source": [
        "# Download dataset from Hugging Face\n",
        "def download_dataset_from_hf(local_dir=\"./\"):\n",
        "    print(\"Downloading dataset from Hugging Face...\")\n",
        "\n",
        "    # Ensure directory exists\n",
        "    os.makedirs(local_dir, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        # Get current logged-in user information\n",
        "        try:\n",
        "            hf_repo_id = \"dragons666/ui2html_results\"\n",
        "            print(f\"Will download from repository: {hf_repo_id}\")\n",
        "        except Exception as e:\n",
        "            hf_repo_id = input(\"Please enter repository ID (format: username/repo-name): \")\n",
        "\n",
        "        # Download zip file\n",
        "        zip_path = hf_hub_download(\n",
        "            repo_id=hf_repo_id,\n",
        "            filename=\"ui2html_results.zip\",\n",
        "            repo_type=\"dataset\"\n",
        "        )\n",
        "        print(f\"Dataset downloaded to: {zip_path}\")\n",
        "\n",
        "        # Extract file\n",
        "        print(f\"Extracting dataset to: {local_dir}\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(local_dir)\n",
        "\n",
        "        print(\"Dataset download and extraction complete\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading dataset: {e}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Cl5AG_4MAXR"
      },
      "outputs": [],
      "source": [
        "# Render HTML to image (Colab compatible version)\n",
        "def render_html_to_image(html_str, output_path):\n",
        "    \"\"\"Use Selenium to render HTML string to image (Colab compatible version)\"\"\"\n",
        "    from selenium import webdriver\n",
        "    from selenium.webdriver.chrome.options import Options\n",
        "    from selenium.webdriver.chrome.service import Service\n",
        "\n",
        "    html_file = f\"/tmp/temp_{int(time.time() * 1000)}.html\"\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "\n",
        "    with open(html_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(html_str)\n",
        "\n",
        "    options = Options()\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    options.add_argument('--window-size=1280x1024')\n",
        "\n",
        "    try:\n",
        "        # ChromeDriver setup for Colab\n",
        "        driver = webdriver.Chrome(options=options)\n",
        "        driver.get(\"file://\" + os.path.abspath(html_file))\n",
        "        time.sleep(1)  # Wait for rendering\n",
        "        driver.save_screenshot(output_path)\n",
        "        driver.quit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error rendering HTML: {e}\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        os.remove(html_file)  # Clean up temporary file\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return output_path\n",
        "\n",
        "# Load CLIP model for similarity calculation\n",
        "def load_clip_model():\n",
        "    print(\"Loading CLIP model for image similarity calculation...\")\n",
        "    from transformers import CLIPProcessor, CLIPModel\n",
        "    clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "    clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "    return clip_model, clip_processor\n",
        "\n",
        "# Get image embedding\n",
        "def get_image_embedding(image_path, clip_model, clip_processor):\n",
        "    \"\"\"Get CLIP embedding for an image\"\"\"\n",
        "    try:\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        inputs = clip_processor(images=image, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            image_embeds = clip_model.get_image_features(**inputs)\n",
        "        return F.normalize(image_embeds, p=2, dim=-1)\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting embedding for image {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Calculate cosine similarity\n",
        "def cosine_similarity(a, b):\n",
        "    \"\"\"Calculate cosine similarity between two embeddings\"\"\"\n",
        "    if a is None or b is None:\n",
        "        return 0.0\n",
        "    return (a @ b.T).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxQN-8MKOge6"
      },
      "outputs": [],
      "source": [
        "# Calculate similarity metrics\n",
        "def calculate_similarity_metrics():\n",
        "    print(\"Calculating similarity metrics...\")\n",
        "\n",
        "    # Ensure render directory exists\n",
        "    os.makedirs(\"test_results/rendered\", exist_ok=True)\n",
        "\n",
        "    # Load base_outputs\n",
        "    try:\n",
        "        with open(\"test_results/base_outputs.json\", \"r\") as f:\n",
        "            base_data = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(\"base_outputs.json not found. Please run the inference script or download the dataset first.\")\n",
        "        return None\n",
        "\n",
        "    # Load ft_results\n",
        "    try:\n",
        "        with open(\"test_results/ft_results.json\", \"r\") as f:\n",
        "            ft_data = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(\"ft_results.json not found. Please run the inference script or download the dataset first.\")\n",
        "        return None\n",
        "\n",
        "    # Convert ft_data to dictionary for faster lookup\n",
        "    ft_dict = {item['sample_id']: item for item in ft_data}\n",
        "\n",
        "    # Load CLIP model\n",
        "    clip_model, clip_processor = load_clip_model()\n",
        "\n",
        "    # Prepare results dictionary\n",
        "    results = {\n",
        "        'sample_id': [],\n",
        "        'original_path': [],\n",
        "        'base_rendered_path': [],\n",
        "        'ft_rendered_path': [],\n",
        "        'base_similarity': [],\n",
        "        'ft_similarity': [],\n",
        "        'improvement': []\n",
        "    }\n",
        "\n",
        "    # Process each sample\n",
        "    for item in tqdm(base_data, desc=\"Processing samples\"):\n",
        "        sample_id = item['sample_id']\n",
        "\n",
        "        # Check if there's a corresponding fine-tuned result\n",
        "        if sample_id not in ft_dict:\n",
        "            print(f\"Sample {sample_id} has no corresponding fine-tuned result, skipping\")\n",
        "            continue\n",
        "\n",
        "        original_path = item['original_path']\n",
        "\n",
        "        base_html = item['base_html']\n",
        "        ft_html = ft_dict[sample_id]['ft_html']\n",
        "\n",
        "        # Render HTML to images\n",
        "        base_rendered_path = render_html_to_image(\n",
        "            base_html,\n",
        "            f\"test_results/rendered/{sample_id}_base.png\"\n",
        "        )\n",
        "\n",
        "        ft_rendered_path = render_html_to_image(\n",
        "            ft_html,\n",
        "            f\"test_results/rendered/{sample_id}_ft.png\"\n",
        "        )\n",
        "\n",
        "        if base_rendered_path is None or ft_rendered_path is None:\n",
        "            print(f\"Rendering failed for sample {sample_id}, skipping\")\n",
        "            continue\n",
        "\n",
        "        # Get embeddings\n",
        "        try:\n",
        "            e_orig = get_image_embedding(original_path, clip_model, clip_processor)\n",
        "            e_base = get_image_embedding(base_rendered_path, clip_model, clip_processor)\n",
        "            e_ft = get_image_embedding(ft_rendered_path, clip_model, clip_processor)\n",
        "\n",
        "            # If any embedding fails, skip this sample\n",
        "            if e_orig is None or e_base is None or e_ft is None:\n",
        "                print(f\"Image embedding extraction failed for sample {sample_id}, skipping\")\n",
        "                continue\n",
        "\n",
        "            # Calculate similarities\n",
        "            base_similarity = cosine_similarity(e_orig, e_base)\n",
        "            ft_similarity = cosine_similarity(e_orig, e_ft)\n",
        "            improvement = ft_similarity - base_similarity\n",
        "\n",
        "            # Store results\n",
        "            results['sample_id'].append(sample_id)\n",
        "            results['original_path'].append(original_path)\n",
        "            results['base_rendered_path'].append(base_rendered_path)\n",
        "            results['ft_rendered_path'].append(ft_rendered_path)\n",
        "            results['base_similarity'].append(base_similarity)\n",
        "            results['ft_similarity'].append(ft_similarity)\n",
        "            results['improvement'].append(improvement)\n",
        "\n",
        "            print(f\"\\n  Base model similarity: {base_similarity:.4f}\")\n",
        "            print(f\"  Fine-tuned model similarity: {ft_similarity:.4f}\")\n",
        "            print(f\"  Improvement: {improvement:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing sample {sample_id}: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Check if there are any results\n",
        "    if len(results['sample_id']) == 0:\n",
        "        print(\"Warning: No samples were successfully processed, cannot generate results\")\n",
        "        return None\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxtsOPLBQPHt"
      },
      "outputs": [],
      "source": [
        "# Generate statistics and visualizations\n",
        "def generate_stats_and_visualizations(results):\n",
        "    print(\"Generating statistics and visualizations...\")\n",
        "\n",
        "    # Create results dataframe\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Save results to CSV\n",
        "    results_df.to_csv(\"test_results/similarity_metrics.csv\", index=False)\n",
        "\n",
        "    # Calculate average metrics\n",
        "    avg_base_similarity = results_df['base_similarity'].mean()\n",
        "    avg_ft_similarity = results_df['ft_similarity'].mean()\n",
        "    avg_improvement = results_df['improvement'].mean()\n",
        "    median_improvement = results_df['improvement'].median()\n",
        "    improvement_percent = (results_df['improvement'] > 0).mean() * 100\n",
        "    unchanged_percent = (results_df['improvement'] == 0).mean() * 100\n",
        "    degraded_percent = (results_df['improvement'] < 0).mean() * 100\n",
        "\n",
        "    # Generate summary statistics\n",
        "    print(\"\\n=== Statistical Summary ===\")\n",
        "    print(f\"Number of test samples: {len(results_df)}\")\n",
        "    print(f\"Base model average similarity: {avg_base_similarity:.4f}\")\n",
        "    print(f\"Fine-tuned model average similarity: {avg_ft_similarity:.4f}\")\n",
        "    print(f\"Average improvement: {avg_improvement:.4f}\")\n",
        "    print(f\"Median improvement: {median_improvement:.4f}\")\n",
        "    print(f\"Percentage of improved samples: {improvement_percent:.2f}%\")\n",
        "    print(f\"Percentage of unchanged samples: {unchanged_percent:.2f}%\")\n",
        "    print(f\"Percentage of degraded samples: {degraded_percent:.2f}%\")\n",
        "\n",
        "    # Save summary to file\n",
        "    with open(\"test_results/summary_stats.txt\", \"w\") as f:\n",
        "        f.write(\"=== Statistical Summary ===\\n\")\n",
        "        f.write(f\"Number of test samples: {len(results_df)}\\n\")\n",
        "        f.write(f\"Base model average similarity: {avg_base_similarity:.4f}\\n\")\n",
        "        f.write(f\"Fine-tuned model average similarity: {avg_ft_similarity:.4f}\\n\")\n",
        "        f.write(f\"Average improvement: {avg_improvement:.4f}\\n\")\n",
        "        f.write(f\"Median improvement: {median_improvement:.4f}\\n\")\n",
        "        f.write(f\"Percentage of improved samples: {improvement_percent:.2f}%\\n\")\n",
        "\n",
        "    # Visualize results\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(results_df['base_similarity'], results_df['ft_similarity'])\n",
        "    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
        "    plt.xlabel('Base Model Similarity')\n",
        "    plt.ylabel('Fine-tuned Model Similarity')\n",
        "    plt.title('Performance Comparison: Base vs Fine-tuned Model')\n",
        "    plt.axis('equal')\n",
        "    plt.grid(True)\n",
        "    plt.savefig(\"test_results/similarity_comparison.png\")\n",
        "    display(plt.gcf())  # Display chart in Colab\n",
        "    plt.close()\n",
        "\n",
        "    # Plot improvement histogram\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(results_df['improvement'], bins=20)\n",
        "    plt.axvline(x=0, color='r', linestyle='--')\n",
        "    plt.xlabel('Improvement (Fine-tuned - Base)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Improvement Histogram')\n",
        "    plt.grid(True)\n",
        "    plt.savefig(\"test_results/improvement_histogram.png\")\n",
        "    display(plt.gcf())  # Display chart in Colab\n",
        "    plt.close()\n",
        "\n",
        "    print(\"\\nTest results saved to test_results/\")\n",
        "    print(\"Visual comparisons saved to test_results/rendered/\")\n",
        "    print(\"Metrics saved to test_results/similarity_metrics.csv\")\n",
        "    print(\"Charts saved to test_results/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSCMJIXMQSDu"
      },
      "outputs": [],
      "source": [
        "# Helper function: Display image comparison in Colab\n",
        "def display_image_comparison(original_path, base_path, ft_path, sample_id):\n",
        "    \"\"\"Display image comparison in Colab\"\"\"\n",
        "    html = f\"\"\"\n",
        "    <div style=\"display: flex; flex-direction: column; align-items: center; margin-bottom: 20px\">\n",
        "        <h3>Sample ID: {sample_id}</h3>\n",
        "        <div style=\"display: flex; justify-content: center;\">\n",
        "            <div style=\"margin: 10px; text-align: center;\">\n",
        "                <img src=\"data:image/png;base64,{image_to_base64(original_path)}\" style=\"max-width: 300px;\" />\n",
        "                <p>Original Image</p>\n",
        "            </div>\n",
        "            <div style=\"margin: 10px; text-align: center;\">\n",
        "                <img src=\"data:image/png;base64,{image_to_base64(base_path)}\" style=\"max-width: 300px;\" />\n",
        "                <p>Base Model Rendering</p>\n",
        "            </div>\n",
        "            <div style=\"margin: 10px; text-align: center;\">\n",
        "                <img src=\"data:image/png;base64,{image_to_base64(ft_path)}\" style=\"max-width: 300px;\" />\n",
        "                <p>Fine-tuned Model Rendering</p>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    display(HTML(html))\n",
        "\n",
        "# Helper function: Convert image to base64\n",
        "def image_to_base64(image_path):\n",
        "    \"\"\"Convert image to base64 string for display in Colab\"\"\"\n",
        "    try:\n",
        "        with open(image_path, \"rb\") as image_file:\n",
        "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting image to base64: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Display comparison results\n",
        "def display_top_improvements(results, n=2):\n",
        "    \"\"\"Display the top n samples with the largest improvements\"\"\"\n",
        "    if results is None:\n",
        "        print(\"No results available\")\n",
        "        return\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    # Sort by improvement\n",
        "    df_sorted = df.sort_values('improvement', ascending=False)\n",
        "\n",
        "    print(f\"\\nDisplaying top {n} samples with the largest improvements:\")\n",
        "    for i, row in df_sorted.head(n).iterrows():\n",
        "        print(f\"\\nSample {row['sample_id']}:\")\n",
        "        print(f\"Base model similarity: {row['base_similarity']:.4f}\")\n",
        "        print(f\"Fine-tuned model similarity: {row['ft_similarity']:.4f}\")\n",
        "        print(f\"Improvement: {row['improvement']:.4f}\")\n",
        "\n",
        "        # Display image comparison\n",
        "        display_image_comparison(\n",
        "            row['original_path'],\n",
        "            row['base_rendered_path'],\n",
        "            row['ft_rendered_path'],\n",
        "            row['sample_id']\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7MaWXY-Qbhr"
      },
      "outputs": [],
      "source": [
        "print(\"Starting UI2HTML statistics and visualization script (Colab compatible version)...\")\n",
        "\n",
        "download_dataset_from_hf()\n",
        "\n",
        "# Calculate similarity metrics\n",
        "results = calculate_similarity_metrics()\n",
        "\n",
        "if results is not None:\n",
        "    # Generate statistics and visualizations\n",
        "    generate_stats_and_visualizations(results)\n",
        "    # Display top improvement samples\n",
        "    display_top_improvements(results)\n",
        "    print(\"Statistics and visualization script execution completed\")\n",
        "else:\n",
        "    print(\"Unable to calculate similarity metrics, script terminated\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
